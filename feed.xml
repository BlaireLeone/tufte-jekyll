<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hogwash</title>
    <description>A spiffy internet webpage</description>
    <link>/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 29 Apr 2021 18:25:41 -0400</pubDate>
    <lastBuildDate>Thu, 29 Apr 2021 18:25:41 -0400</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>Part Two - Autonomous Vehicles and Bicycles</title>
        <description>&lt;p&gt;&lt;span class=&quot;newthought&quot;&gt;What makes an autonomous vehicle autonomous? And how safe are they really?&lt;/span&gt;&lt;/p&gt;
&lt;figure&gt;&lt;img src=&quot;/assets/img/Bicycles_AVs/bicycle-car-sensor-technology.jpg&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;strong&gt;Driverless-ness, in general, is a tall order&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;While certainly more than the sum of its parts, when disassembled, we can see the complex systems that AVs must employ to function. Among technologies like GPS and automatic braking and steering, Alan Amici, vice president of TE Connectivity, also &lt;a href=&quot;https://www.fi.edu/science-of-selfdriving-cars&quot;&gt;identifies the 3 most essential AV elements&lt;/a&gt;: sensors, connectivity, and software/control algorithms.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Sensors&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Sensors are pivotal to the car’s ability to navigate and more than that, they do the data groundwork, feeding information to the other systems to build from. Sensors must observe their surroundings, detect objects on all sides, identify lane boundaries or curves in the road, etc. We see these sensors in the form of 3 basic technologies working simultaneously: 360-degree LIDAR and radar for short and long range object detection&lt;label for=&quot;3&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;3&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;&lt;a href=&quot;https://www.thedrive.com/article/16916/lidar-vs-radar-pros-and-cons-of-different-autonomous-driving-technologies&quot;&gt;This article&lt;/a&gt; discusses how LIDAR and radar work, their differences, pros and cons, and which of the two sensors individual AV companies prefer &lt;/span&gt;, cameras for cross-checking object recognition, and ultrasound for park assist.&lt;/p&gt;

&lt;p&gt;These provide the AVs with a visual field comparable to the human eye, allowing them to “see” as a human would and orient themselves in relation to the objects around them. While sensors, at the moment, may not out-compete a human eye, several benefits of this technology are that sensors are constantly vigilant, consistent in their estimations, and attending to all sides of the vehicle at once.&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;/assets/img/Bicycles_AVs/Sensors.png&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;Each individual sensor&amp;#8217;s visual field.&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;&lt;em&gt;Algorithms&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;All this sensory data, however, is useless to a system that can’t make confident, human-esque decisions; it needs an on-deck computer system to compile information and learn from the data accumulated until it has developed a situationally-aware, and in some ways, superhuman system &lt;label for=&quot;3&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;3&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;I won’t go into the different kinds of AI models employed by AV’s, however &lt;a href=&quot;https://www.jdsupra.com/legalnews/the-basics-of-autonomous-vehicles-part-35016/&quot;&gt;this article&lt;/a&gt; details many of the commonly used algorithms. &lt;/span&gt;. In other words, it needs AI. And like a teenager with a learner’s permit, the system garners skill through experience. In doing so, the algorithm learns to discriminate between ambiguous objects like a plastic bag and a child, a shady patch and a pothole, or highway construction and a cyclist.&lt;/p&gt;

&lt;p&gt;For the most part, AVs use neural networks, a machine learning tool modeled off the human brain. The networks, once fed a sufficient amount of images, let’s say of a bicycle (think of the copious amount of images parlayed through the captcha assignments to prove humanity), will eventually ascertain for itself what a bicycle is without being told. The images prime the model in a training setting, so it understands what it is looking at in the ‘real’ world. Once it identifies a bicyclist as such, the model can then make a decision. Its next move may be to consciously give the bicyclist 3 feet of breathing room while passing. Among the 50+ companies involved with autonomous vehicles, there are dozens of models available. I’ll discuss one company’s model in more detail later.&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;/assets/img/Bicycles_AVs/How AVs work.jpg&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;This image from Nissan summarizes the algorithmic process succinctly.&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Not only do these models need to identify &lt;em&gt;what&lt;/em&gt; they are looking at, they are also need to reconcile how fast and in what direction surrounding objects are moving. And in doing so, an algorithm should be able to predict the movements of these objects to inform its own navigational decisions. For instance, if the vehicle wants to switch lanes, it must determine if any entity is currently occupying the space it seeks to fill, or if there is an approaching vehicle about to pass. If so, it must calculate that vehicle’s speed and adjust accordingly. Alternatively, if a deer runs across the road, while perhaps unpredictable, it would be useful to know if that deer would already be out of the lane by the time the vehicle gets there. Thus, in calculating the deer’s speed and direction (or in other words, its velocity) the AI may determine if it only needs to slow down instead of stop, perhaps saving its passengers unnecessary stress.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Connectivity&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Lastly, while the AVs are fully operational with just sensors and algorithms, they also need input from surrounding vehicles or wireless hubs (i.e. connectivity) if they are to be more efficient and operate in proximity. These connections could provide weather and traffic updates, road closure information, and input from surrounding AVs.&lt;/p&gt;

&lt;p&gt;The picture below summarizes the big 5 in AV wireless tech.&lt;/p&gt;

&lt;p&gt;The 5 Points of Connectivity:&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;/assets/img/Bicycles_AVs/connectivity areas.png&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;V2P &lt;em&gt;(Vehicle to Pedestrian)&lt;/em&gt; - this could refer either to linking with a pedestrian’s phone or a device worn by the pedestrian to locate them in relation to the vehicle&lt;/li&gt;
  &lt;li&gt;V2V &lt;em&gt;(Vehicle to Vehicle)&lt;/em&gt; - this refers to the picture above, in which all AVs in proximity are connected and communicating to avoid dangerous situations, or else  make transportation more efficient&lt;/li&gt;
  &lt;li&gt;V2I &lt;em&gt;(Vehicle to Infrastructure)&lt;/em&gt; - as this image notes, V2I allows the vehicles to connect with local stoplights, and the like, to inform them that the vehicle is approaching. While not a necessity in most situations, this would be useful if the AV were stopped at a stoplight, with no other vehicles around. The AV could, thus,communicate its position and turn the light green.&lt;/li&gt;
  &lt;li&gt;V2D &lt;em&gt;(Vehicle to Device)&lt;/em&gt; - As the image says, this kind of connection would hook in with local devices to gather information, like images from a camera detailing a traffic accident, or sensors around intersections beeping for a pedestrian walking. This could include pedestrian smart phones as well.&lt;/li&gt;
  &lt;li&gt;V2X &lt;em&gt;(Vehicle to Everything)&lt;/em&gt; -  This encompasses everything else that doesn’t fall under the other headers. This includes individual objects such as trees, buildings, rocks and the like, which may have sensors attached to them to inform AVs of their location. This could be helpful in circumnavigating unique roadway situations where a tree, for instance, is situated very closely to the road. The vehicle may mistake it for a pedestrian or cyclist, of which, it would need to provide extra space for.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;V2V communication is especially important in avoiding dangerous situations between AVs. If a vehicle decides to stop because it thinks the plastic bag is a child, it needs to provide a forewarning to the next vehicle that it’s stopping, so the next car may simultaneously and safely stop or else provide a wide berth. Additionally, fleets of AVs on the roadway, if not interconnected, may be dangerous, if not simply inefficient. Take for example two AVs arriving at an intersection at the exact same time. While AEBs may prevent them from running into each other, without the ability to communicate, the AVs may become locked in an interminable stalemate as they attempt to navigate past each other. That may only occur, however, if they aren’t able to communicate their intentions and synchronize their movements. Thus, AVs cannot operate safely on independent systems. Check out the image below for more examples where connected AVs can avoid tricky situations.&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;/assets/img/Bicycles_AVs/V2V.png&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Beyond safety, connectivity could also boost efficiency overall. Traffic could synchronize  &lt;label for=&quot;4&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;4&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Check out &lt;a href=&quot;https://www.youtube.com/watch?v=iHzzSao6ypE&amp;amp;t=253s&quot;&gt;this video&lt;/a&gt; on how phantom traffic forms and &lt;a href=&quot;https://www.youtube.com/watch?v=TNokBgtSUvQ&amp;amp;t=255s&quot;&gt;this video&lt;/a&gt; for a more detailed look. While I prefer the first video because it provides more information in less time, the animation in the second video is hard to beat. &lt;/span&gt;, eliminating the-mile-long start/stop jerking; stop lights could become non-existent, intersections in general would need little oversight. In a large intersection, vehicles would automatically make space for each other. And, an overarching algorithmic system, essentially acting as an air traffic controller, could calculate each vehicle’s route, determine where they will be at any given moment, and ultimately, minimize everyone’s time in traffic. Vehicles could also receive moment by moment reports from traffic and accident centers, like The Department of Transportation, local newscasters, or Google Maps. This could be a boon for a vehicle’s passengers; AVs could automatically switch routes due to road closures, traffic, or iciness, saving passengers time and reducing contact with safety hazards.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Research and Regulation&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Collectively, these technologies form a functional efficient system that, with enough reliable sensors, combined with robust programming, and wireless information boosts could be more preferable, and especially safer, than conventional vehicles, driven by an imperfect, inconsistent human. According to the US Department of Transportation (USDOT), &lt;a href=&quot;https://www.nhtsa.gov/press-releases/usdot-releases-2016-fatal-traffic-crash-data&quot;&gt;94% of serious collisions&lt;/a&gt; are linked to error in human decision making, a statistic thrown around by manufacturers and policy makers who hope to leverage AVs as the alternative transportation we need due to their progressive safety measures. I’ll dissect this statistic later on, as it is a little more nuanced than it seems, but, assuming humans to be at fault of all but a handful of incidents, it’s assumed that taking humans out of driving will make our roads a safer place. But are AVs actually better than the 94% error rate of humans?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Despite popular sensationalist belief, head on collisions are not representative of most of the kinds of accidents that self-driving vehicles engage in&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In the US especially, we are prone to think that fatal high-speed collisions are the norm for AVs, given media coverage of such incidents as Elaine Herzberg’s, the first pedestrian-related fatality, (who I will discuss later) and also Tesla’s &lt;a href=&quot;https://nypost.com/2021/03/19/feds-probing-nearly-two-dozen-crashes-involving-tesla-cars/&quot;&gt;numerous highway crashes&lt;/a&gt; &lt;label for=&quot;&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/Bicycles_AVs/Tesla_Semi_Truck_Crash.jpeg&quot; /&gt;&lt;br /&gt;This Tesla mistook the side of a semi-truck for a far-off billboard&lt;/span&gt;(although, as stated in the last article, Tesla does not manufacture self-driving vehicles. They manufacture the idea of a self-driving vehicle with their mis-characterized ‘full self-driving’ vehicle package that does not exceed a level 3 on SAE’s AV characterization chart. This means they should never be driven unmonitored, even in autopilot mode. But an average driver wouldn’t know that given that they are buying a nominally recognized ‘full self-driving’ vehicle). Nonetheless, &lt;a href=&quot;http://www.umich.edu/~umtriswt/PDF/UMTRI-2015-34_Abstract_English.pdf]&quot;&gt;tentative research&lt;/a&gt; from 2019 has shown that the opposite is actually true; rear-end collisions encompass the majority of AV accidents at 64.2%, a staggeringly high number considering that the next most frequent accident type for AVs are angle crashes (those that mostly occur at intersections with cars traveling perpendicularly or at an angle) at 31.4%. Even &lt;a href=&quot;https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812981&quot;&gt;conventional vehicles&lt;/a&gt; (CVs)&lt;label for=&quot;2&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;2&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;CV can also stand for connected vehicle, in reference to wireless connection, but in this case I refer to CVs exclusively as conventional vehicles &lt;/span&gt; with a human driver don’t get close to that rear-ending stat; only 28.3% of motor vehicle accidents in the US are rear-ends - though rear-end and angle collisions are still the first and second most common crash type even for conventional vehicles.&lt;label for=&quot;3&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;3&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;It is unclear if the research was controlling for where the vehicles were driven - if they are mostly driven on the highway, chances of crashing at an angle are low, which could explain the low angle crash figures &lt;/span&gt;&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;/assets/img/Bicycles_AVs/Angle crash.jpeg&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;On top of all that, AVs are far more likely to be rear-ended by other vehicles than to do the rear-ending themselves. It’s speculated that this is due to the unconventional way AVs drive. In sticking to the letter of the law as they are programmed to do, they tend to confuse human drivers who are more likely to speed, tailgate, hug the side line, shoot the gaps etc. And, as AVs are hyper aware of any pedestrians or vehicles in front of them, they are more likely to fully stop for a pedestrian’s protection, encountering situations where human drivers may instead slow down, make a wide berth, or, if what the AV was perceiving wasn’t actually another person at all, keep on at normal speed.&lt;/p&gt;

&lt;p&gt;Perhaps not surprisingly, because of this, AVs have a higher accident rate per miles traveled than conventional vehicles. A study from 2015 calculated that human drivers averaged anywhere from 1.9 – 4.1 crashes per million miles (cpmm) traveled.&lt;label for=&quot;2&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;2&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;The variability is due to how many crashes tend not to be reported for insurance reasons, liability, and the like. Though 1.9 cpmm is a fixed number from the DMV, the researchers here estimated unreported crashes as well, and put the actual US crash rate at about 4.1cpmm. &lt;/span&gt; AVs, on the other hand, average about 9.1cpmm. An alarming stat on the surface; however, as these accidents are largely in the form of rear-endings from other vehicles, they are not nearly as fatal or injurious as conventional vehicle crashes. On top of that, almost ¾ of the crashes occurred with the AV going at a speed of 5mph or lower. This again, is probably due to the excessively cautious driving style employed by AVs, however, it should also be noted that the report doesn’t detail how fast the other vehicles were going and, thus, how great of an impact the other drivers felt.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Limitations&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;While this study, &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S2352146520301654&quot;&gt;and others like it&lt;/a&gt;, provide confident results, three caveats need to be recognized.&lt;/p&gt;

&lt;p&gt;1.) Most importantly, AVs don’t exist in the quantities needed to make meaningful comparisons with conventional vehicles. The data acquired from the DMV &lt;label for=&quot;3&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;3&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;AV manufacturers are required to report any crash or collision involving AVs within 10 days to the DMV. &lt;/span&gt; of combined accident rates for conventional vehicles totals nearly 3 trillion miles as opposed to 1.2 million by AVs. Put another way, that’s 1 AV mile for every 2,500,000 CV mile. In fact, &lt;a href=&quot;https://www.rand.org/content/dam/rand/pubs/research_reports/RR1400/RR1478/RAND_RR1478.pdf&quot;&gt;a report&lt;/a&gt; released by the RAND corporation (a nonprofit research institution) concludes that 100 AVs driving 24 hours a day, 365 days of the year, at an average speed of 25 mph, would need to drive for 12.5 years, or 275 million miles, to conclude with 95% confidence that their failure rate leads to at most 1.09 deaths per 100 million miles. That’s a lot of numbers to process, but in essence, the sample size of the previous study, and all others like it, will be too small to make any generalizable statements until AVs have driven long enough, which will take some time (about 12 years according to the study, however, the study doesn’t factor in how many more self-driving vehicles will have been manufactured since then, so the timing should be significantly less).&lt;/p&gt;

&lt;p&gt;2.) Another limitation the study notes is the context of the vehicle testing, or more specifically, where the vehicles were not tested – icy, stormy, or geographically unstable areas, or otherwise dangerous conditions. It’s unclear how many AVs are involved in accidents due to weather or roadway circumstances. Outside of untoward situations, location in general could affect AV crash rates. In figures from a report released by Waymo in 2021, Chandler, Arizona had nearly twice as many cross-traffic AV accidents than the Phoenix Metropolitan Area, and nearly 3x as many as the rest of the US testing grounds. This could be due to local driving customs or road attitudes, or physical conditions as noted above. However, these stats should be taken with a grain of salt as the report does not detail how many crashes total occurred in each area. But regardless, it should be noted that AV collision results could significantly differ depending on their location. &lt;label for=&quot;&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/Bicycles_AVs/Waymo in Arizona.gif&quot; /&gt;&lt;br /&gt;Waymos introduction to Phoenix&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;3.) The report specifies that the AVs were not at fault for any accident they were involved in, however, it’s unclear what they mean by “fault”. It could mean that the AVs didn’t do the colliding, (they were in fact the collidees) and by that metric, it wasn’t the AV’s fault. In fact, the fault in this situation is implicitly placed on the CV driver. Or it could mean that the situations where the AVs were collided with were entirely justified (as in there may have been a pedestrian in the road) and, therefore, were not the AVs fault. And here, the fault is diffused to all parties, and therefore, no one is truly to blame. Either way, as it has been suggested that so many rear-end accidents with AVs occurred because human drivers were surprised by the AVs behavior, I believe there is room to allow for AV culpability. If AVs are not following the intuitive rules of the road that every other driver subscribes to, they may lead to accidents that may not have happened otherwise, regardless of speed or impact intensity. Thus, I believe it’s prudent to reserve judgment on the exact safety integrity of these stats until more information can be obtained.&lt;/p&gt;

&lt;p&gt;Despite these limitations, the results are tentatively exciting, but without enough data, we can’t say conclusively whether they are truly safer than human drivers, or else safe in general. More than that, it’s still unclear how they interact with cyclists - of which, I will tackle in the next article.&lt;/p&gt;
</description>
        <pubDate>Mon, 08 Mar 2021 03:57:31 -0500</pubDate>
        <link>/articles/21/Bikes_Part_2</link>
        <guid isPermaLink="true">/articles/21/Bikes_Part_2</guid>
        
        
        <category>jekyll</category>
        
        <category>css</category>
        
      </item>
    
      <item>
        <title>Part One - Autonomous Vehicles and Bicycles</title>
        <description>&lt;p&gt;&lt;span class=&quot;newthought&quot;&gt;Autonomous vehicle technology is projected to revolutionize the transportation industry - but do we know how they interact with bicyclists?&lt;/span&gt;&lt;/p&gt;
&lt;figure&gt;&lt;img src=&quot;/assets/img/Bicycles_AVs/MastHead.jpg&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;strong&gt;Bicyclists have had a contentious history with vehicles&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Given their lack of protection, a bicyclist finding themselves unexpectedly in a vehicle’s path will more than likely result in the &lt;a href=&quot;cyclist injured&quot;&gt;cyclist being injured&lt;/a&gt; if not killed. In &lt;a href=&quot;https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812765&quot;&gt;2017&lt;/a&gt;, 783 bicyclists died on US roadways; &lt;label for=&quot;1&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;1&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;This report was released by the National Highway Traffic Safety Administration. Unfortunately, I couldn’t pin down more recent stats. Also, they refer to cyclists as pedalcyclists here to include unicycles, tricycles, nonmotorized vehicles, and the like. I will only use bicyclists and cyclists in this article, but it’s important to note that these stats may be skewed as they include other kinds of pedal-operated vehicles. &lt;/span&gt; 96% (or 753) of those deaths involved a vehicle. Most of the time, this is due to simply not seeing the cyclist - bikes are small and often situated below the driver’s line of sight, and because of their maneuverability, they zip through traffic, perhaps coming up on a driver unawares; a driver may also neglect to check for bicyclists nearby, as happens when opening a door into a bike lane. Either way, drivers are liable to fatally injure a cyclist whether they realize it or not. Take for example, &lt;a href=&quot;https://www.rd.com/article/run-over-by-an-eighteen-wheeler/&quot;&gt;Katie Mckenna&lt;/a&gt;, a New York cyclist turned author and motivational speaker. She was run over by a semi-truck when it failed to notice her while making a right turn at an intersection. In &lt;a href=&quot;https://www.amazon.com/How-Get-Run-Over-Truck-ebook/dp/B01LY9PYBR&quot;&gt;her book&lt;/a&gt;, she pulls no punches when identifying bicyclist’s vulnerability on the roadway; the first line queries, “So, how do you get run over by a truck? My first recommendation is to ride a bicycle”. According to her book, she signaled in every way possible that she was there. This is a sensationalist example, but one that exemplifies a common problem bicyclists have with surrounding vehicles – a lack of attention.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;My Friend Tom&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A roommate of mine, Tom, came home one day with a bandaged hand, bruised face, and a general look of shock and bewilderment. He had just come from the hospital after hitting a car on his bike. A negligent happenstance for some, but a truly unlucky feat for Tom.&lt;/p&gt;

&lt;p&gt;Here’s what he told me:&lt;/p&gt;

&lt;p&gt;While riding into town, post-COVID shutdowns, the streets were empty. This was around the start of quarantine, early April 2020 - hardly anyone was out. Nonetheless, Tom encountered one vehicle on his way.&lt;/p&gt;

&lt;p&gt;After shooting down a short, but steep hill, Tom came up on a mid-sized SUV. He was still coasting from the downhill and hoped to use this momentum for an easier ride on the subsequent flat part coming into town.&lt;/p&gt;

&lt;p&gt;Tom was accelerating so fast from the momentum, he started making moves to pass the car ahead of him. As he was coming up on the car’s back right bumper, but still a reasonable distance behind, a pedestrian streaked across the road ahead of the car. As Tom put it, the person appeared out of nowhere, whooped and sprinted through the crosswalk, then disappeared into a nearby park. And though the car was still a good distance from the crosswalk, it executed a full stop, the back wheels swinging into the bike lane.&lt;/p&gt;

&lt;p&gt;Tom, still trying to maximize his speed from the downhill, ran arm-first into the back window, while his face swung around and hit the side of the car. His hand, probably in trying to brace himself, punched through the bottom right corner of the back window and his arm went through all the way up to the shoulder.&lt;/p&gt;

&lt;p&gt;While this may seem like a clear case of an over-reactive driver, the driver, in fact, was not at fault. Instead, the car, a fresh-off-the-lot 2021 vehicle installed with an automatic emergency braking system (AEB), had made the decision to stop. Even though the car was far enough from the pedestrian for the driver to consciously reduce his speed, and even though the whooper/sprinter was speeding so fast through the crosswalk that the car wouldn’t have hit him regardless (according to Tom), the car had recognized a potential target and literally skidded to a halt.&lt;/p&gt;

&lt;p&gt;Both Tom and the driver paid for it, the driver in repairing his new car, and Tom with his medical bills and newly cracked bike frame.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;So, what does this mean?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I believe there are several takeaways from this story, perhaps the least of which is the question of when it’s prudent for a cyclist to rely on coasting. Tom had hoped to use the momentum from the downhill to ease his pedaling; I think most experienced cyclists have leant on passive energy for speed and ease of riding (plus, there’s a special kind of satisfaction derived from passing a car on your bike, especially while half-coasting). His determination to go faster, however, brought him in the line of fire. Which brings up another question: Is it right to pass another vehicle in such proximity when they are the only other vehicle on the roadway? Legality aside, is doing so inconsiderate if not rash? In retrospect, Tom acknowledges that his attempt at overtaking may have been reckless. Given the flatness of the road, Tom’s experience as a cyclist, and the lightness of his bike, he had no need to save himself the pedaling effort nor outpace the only other vehicle on the roadway.&lt;/p&gt;

&lt;p&gt;But the question I ultimately believe to be most poignant here is that of how autonomous vehicles (AVs) will coalesce with bicyclists in the future. I don’t believe one could truly attribute Tom’s accident to the AEBs, given that they were attempting to save the driver and pedestrian from needless harm. However, the fact that an accident resulted nonetheless suggests a need for further analysis of how autonomous vehicles in general interact with bicyclists, as they may not prioritize bicyclist’s safety as highly as they should.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;But first – A Little Background&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;What technology allows autonomous vehicles to be autonomous? And is it fair to question AVs in general despite Tom’s story only featuring AEBs?&lt;/p&gt;

&lt;p&gt;In short, autonomous here means driver-less, or else, having little to no need for human supervision. But within this, AVs can be deconstructed into ascending levels of autonomy. The Society of Automotive Engineers (SAE) categorized AVs in 2013, and then &lt;a href=&quot;https://www.sae.org/news/press-room/2018/12/sae-international-releases-updated-visual-chart-for-its-&amp;quot;levels-of-driving-automation&amp;quot;-standard-for-self-driving-vehicles&quot;&gt;updated them again&lt;/a&gt; in 2018, developing 6 tiers of automation, from Level 0, in which the vehicle only makes suggestions to a human driver and occasionally takes over (as evident in Tom’s braking case), to Level 5, where the vehicle has complete control and passengers have confidence in not supervising. Between Levels 2 to 3, is the threshold between the human’s and vehicle’s control; in other words, Level 3 signals the beginning of vehicle autonomy. Despite some company’s misleading advertising, like Tesla’s “&lt;a href=&quot;https://www.thedrive.com/news/26700/tesla-puts-full-self-driving-back-on-the-menu-but-its-not-what-you-think&quot;&gt;full self-driving&lt;/a&gt;” tech package, as yet, no company involved with AV technology has reached level 5. The table below details each level.&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;/assets/img/Bicycles_AVs/AVs level of Autonomy 3.jpg&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;Before the update in 2018 only 5 levels existed, 0-4. As technology progressed, Level 4 developed a part (a) and (b). Part (b) was eventually bisected into a separate level - Level 5. Images detailing AV tech, history, and projections refer to fully autonomous as Level 4 or Level 5 depending on when they were created.&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Looking back at Tom’s story, we don’t see a Level 5 driverless vehicle. Instead, his experience features a human-driven car equipped with AEBs, a form of brake assist designed to help the driver identify and avoid head on collisions, putting this vehicle at a Level 0/Level 1, according to SAE’s interpretation. &lt;label for=&quot;1&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;1&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;It’s also worth noting, that since SAE created the autonomy levels, they have taken on a life of their own. It’s unclear if SAE sanctioned any of the changes or if they were simplified via the proverbial ‘telephone’ process. Many other sources would not characterize AEBs at Level 1 at the least. &lt;/span&gt;&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;/assets/img/Bicycles_AVs/AEB.jpg&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;These brakes become operational with a command from a computer that receives information from built-in sensors. When these sensors detect possible impending obstacles, they relay that data to the computer, which decides if they are, indeed, obstacles to be avoided; if so, the computer gives the word to brake. In other words, AEBs are a low-level form of artificial intelligence (AI). Like AEB’s, AI makes decisions according to information it receives. While the AI of today is getting increasingly more complicated, analyzing a broader spectrum of data in more depth and outputting information akin to a human’s intelligence (and in many ways faster), at their core they operate by gathering, synthesizing, and processing data. Principally, this process is the same as an AEB’s decision making, and therefore, an AV’s decision making as well.&lt;/p&gt;

&lt;p&gt;Thus, despite Tom’s brush with what could be considered a limited version of AI, these brakes are in fact the immature fledglings of a fully autonomous vehicle. More than that, the AVs of today are intended by some to be the prototype of a nationwide fleet of vehicles.  &lt;a href=&quot;https://www.ghsa.org/resources/spotlight-av17&quot;&gt;Projections from the Governors Highway Safety Association&lt;/a&gt; (GHSA) predict anywhere from 20 - 40% of vehicles manufactured by 2040 will be autonomous.&lt;/p&gt;

&lt;figure class=&quot;fullwidth&quot;&gt;&lt;img src=&quot;/assets/img/Bicycles_AVs/TIMELINE-TO-FULL-CAR-AUTOMATION.png&quot; /&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Already, the technology that enables AVs has grown exponentially in the last decade, to the point where we currently see functioning Level 4 vehicles on roadways worldwide (albeit on a trial level as most are still under supervision, and prone to adjustments as the systems run into novel situations). And progress begets progress, as they say. Given this projected eventuality, I believe it’s fair to interrogate the nature of AVs in general, as they are poised to be the next greatest technological advancement since the bread slicer gave us sliced bread.&lt;/p&gt;

&lt;p&gt;Despite their potential, however, AV technology is developing faster than the policies to regulate them. Without firm regulatory guidelines, not all of the AVs, or even Level 3 AVs, on the market today are put through the same safety procedures with the same testing rigor and level of algorithmic standards; both Tesla and Uber have infamously mis-advertised or cut corners on their products, leading to unnecessary casualties - the only silver lining with these events however, is that they hopefully provided an impetus for policy and regulation. Furthermore, outside of the issue of safety, are the long-term, big picture questions. Do we really need AVs at all? Will they holistically improve our current system? Or should we be focusing our energies instead on more alternative sustainable transportations (like biking!)? As AV interest intensifies, will it divert time, attention, and funding away from multi-modal transportation, which may be better in the long term- for our physical and mental health with more exercise, our environmental health with less pollution, and our societal health with more town center city planning that focuses less on traffic diversion and highway management, and more on communal spaces? Or perhaps we do need AVs, but only in limited locations with limited fleets. Essentially, before we start regulating, we need to ask ourselves, what kind of society do we want to be?&lt;/p&gt;

&lt;p&gt;This series isn’t designed to answer any of the above questions, but I believe they are important to ask. Regardless of our intentionality, our transportation preferences affect how our society is shaped and our we interact as people. I believe bicycling to be the most future forward mode of transportation, given projections of population growth and climate change, thus, how AV technology accommodates bicyclists is an important factor in adjusting for this new technology. With all this in mind, I’ll evaluate the ways in which AVs interact with bicyclists and the technology advancements that include cyclist awareness.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Autonomous Vehicle events&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;While not necessary for this article, it’s also interesting to see how far autonomous vehicle technology has come, and more than that, how quickly. I’m sure visions of self-driving vehicles existed previous to these milestones, but officially, as a population, we have been imagining an automated world for almost one hundred years.&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;/assets/img/Bicycles_AVs/AVs timeline.jpg&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;This image outlines important milestones in automation history, however, it misses a few key pitstops. 1.) In 1939, Norman Bel Geddes created the &lt;a href=&quot;https://www.sensesatlas.com/territory/architecture/futurama-the-prototype-of-the-american-highway-city/&quot;&gt;Futurama exhibit&lt;/a&gt; in New York’s 1939 World’s Fair, sponsored by General Motors, and featuring an automated highway. The exhibit imagined the world 20 years in the future and was the largest scale model in history. 2.) More importantly to current technological advancements, in 1986, German engineer &lt;a href=&quot;https://www.politico.eu/article/delf-driving-car-born-1986-ernst-dickmanns-mercedes/&quot;&gt;Ernst Dickmann&lt;/a&gt; outfitted a Mercedes-Benz van with autonomous technology and drove it around his university campus. He then began a partnership with German car manufacturer Daimler; Dickmann’s vision is just recently coming to fruition as social experimentation and technology are converging. 3.) This image mentions the creation of the &lt;a href=&quot;https://www.darpa.mil/work-with-us/public/prizes&quot;&gt;DARPA Grand Challenge&lt;/a&gt; in 2004, funded by the Defense Advanced Research Projects Agency, a branch of the US Department of Defense. What this image does not mention, however, is that the first two challenges were long distance races located in the Mojave Desert with a 1 and then 2-million-dollar prize. The third challenge, in 2007, was an Urban course, located at an Air Force Base in California. Prizes were again $2 million dollars. DARPA has since continued with cyber, space launch, and subterranean challenges. 4.) In 2015, the &lt;a href=&quot;https://www.autoblog.com/2015/04/03/delphi-thrilled-with-results-from-autonomous-cars-cross-country/&quot;&gt;Delphi Automotive&lt;/a&gt; driverless car becomes the first AV to complete a transcontinental trip from San Francisco to NYC. It completed it in 9 days. 5.) And in 2016, Singapore introduced its first autonomous taxi service, &lt;a href=&quot;https://spectrum.ieee.org/cars-that-think/transportation/self-driving/nutonomy-to-launch-worlds-first-fully-autonomous-taxi-service-in-singapore-this-year&quot;&gt;MIT’s nuTonomy&lt;/a&gt;, to its streets.&lt;/figcaption&gt;&lt;/figure&gt;
</description>
        <pubDate>Sat, 27 Feb 2021 06:45:00 -0500</pubDate>
        <link>/articles/21/Bikes</link>
        <guid isPermaLink="true">/articles/21/Bikes</guid>
        
        
        <category>jekyll</category>
        
        <category>css</category>
        
      </item>
    
      <item>
        <title>Part Two - The Genesis of Machine Learning: Why Neural Networks look like Our Brains</title>
        <description>&lt;p&gt;&lt;span class=&quot;newthought&quot;&gt;Connectionism: how our brains learn and make decisions iteratively.&lt;/span&gt;&lt;/p&gt;
&lt;figure&gt;&lt;img src=&quot;/assets/img/Brains_ML/InfoBottleneck_2880x1620.jpg&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;strong&gt;Dogs again&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So why would a growling dog prompt a fight/flight reaction, when previously we wanted to pet them? Perhaps we saw a gruesome attach scene in a movie, or we were bit by a dog in the past, or we were taught to give dogs their space. Regardless, at one point, we didn’t understand the potential of a growling dog, and now we do. We learned – and our brains adjusted. At the outset of learning that a growling dog might be harmful, our brains created new neurons, connecting them with the old ones that represent ‘dog’. Our brains may even have reformed the concept of ‘dog’ entirely.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Original feelings towards dogs:&lt;/em&gt;&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;/assets/img/ML flow chart 1.png&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;&lt;em&gt;After getting bit by dog:&lt;/em&gt;&lt;/p&gt;

&lt;figure&gt;&lt;img src=&quot;/assets/img/ML flow chart 2.png&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Originally, this flow of decision making just included ‘pet’, but now it has ‘harmful’ and ‘run. Our next interaction with a dog may find them to be not harmful, but also totally unresponsive to petting, and thus we add ‘ignore’ to our responses.&lt;/p&gt;

&lt;figure class=&quot;fullwidth&quot;&gt;&lt;img src=&quot;/assets/img/ML flow chart 3.png&quot; /&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;As stated, this is an oversimplified example. Our brains are so complex and well-optimized that contextual variability is added to the equation in an instant. At the same time the chain of decisions is made, outside information is simultaneously considered. &lt;label for=&quot;troyandabed&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;troyandabed&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/fluffy_the_three_headed_dog.jpg&quot; /&gt;&lt;br /&gt;Lots of information to glean from Fluffy.&lt;/span&gt; The dog may be attached to a leash, it may be growling at the other dog we happen to have with us, it may not be growling at all, but have its lips pulled back in a permanent snarl. We may also see a fence within running distance or perhaps its owner assures us it’s friendly, something we may be likely to believe because the owner is a trusted friend. Our brains process and respond to all of this information in an instant. And we add it to our decision tree.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Frequent vs Infrequent experiences&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Over time, the more experiences we have with dogs (whether on tv, in person, or through a story), the better we can fine-tune our decision making. We may start to notice correlations between breeds, sizes, hair length, geographic location, emaciation, age, or nearby animals. The more information we attend to and add to our system, the more adept will be at responding to future experiences.&lt;/p&gt;

&lt;p&gt;As these experiences accumulate, they simultaneously create new connections for new information, and strengthen connections from previous experiences. And these &lt;a href=&quot;http://scienceoflearning.jhu.edu/research/how-does-learning-impact-neural-networks-in-the-primary-visual-cortex&quot;&gt;neural connections get stronger&lt;/a&gt; according to the frequency of the results we get. And the stronger the connection, the more often our brains will visit that cluster to make an “informed” decision; or what one might call logic. Thus, if the neural connection between ‘dog’ and ‘run’ is stronger than ‘dog’ and ‘pet’, we will run.&lt;/p&gt;

&lt;p&gt;On the flip side, for those experiences that happen infrequently, we probably will still remember, but due to their infrequency, we don’t visit the connection very often to influence our decisions. Take the example of running into a low hanging/descending doorway, perhaps in a corridor we are unfamiliar with. If this doorway is one we don’t frequent very often, than we are unlikely to take it very seriously within the grand scheme of doorways. We may run into the doorway a few times while visiting the corridor, and after a few times, we may, subconsciously or otherwise, get into the habit of ducking for this particular doorway. &lt;label for=&quot;storm trooper&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;storm trooper&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/Hitting head on doorway.jpg&quot; /&gt;&lt;br /&gt;The &lt;del&gt;force&lt;/del&gt; neural pathway is &lt;del&gt;strong&lt;/del&gt; weak with this one.&lt;/span&gt; But take the corridor away and replace it with the normal doorways we are apt to come across, and we no longer duck. The habit of ducking was unable to be ingrained because this is not a situation we normally find ourselves. Thus, the connection we made between doorway and duck while we visited the corridor dies, as we no longer need it. Thus, neuron connections also get weaker, the less frequently we visit them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Recency, Common Sense, and Emotions - Oh My!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;It’s important to note, that our decisions don’t always go through the chain of reasoning as described in the dog example above. We can override them for a variety of reasons: perhaps the last experience we had was unlike the majority and the recency of that event stands out to us more clearly than the strongest neuron cluster. Or perhaps we are in search of the Philosopher’s Stone and must bypass the three-headed dog standing over the trap door we must enter by mustering up the gumption to face our ‘common sense’ (or in this case, what our brains tell us we should avoid).&lt;/p&gt;

&lt;p&gt;&lt;label for=&quot;troyandabed&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;troyandabed&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/Troy_and_abed.jpg&quot; /&gt;&lt;br /&gt;Troy and Abed&lt;/span&gt;
Our decision making is often influenced by our emotions as well. As anyone with even a hint of a phobia can attest to, we can be influenced to avoid something due to an extreme emotional experience, even if we logically understand that we aren’t in danger. Likewise, but to a much lesser degree, how many decisions are made whilst trying to calculate every angle, but in the end, finding this to be a tedious task, and instead picking the one that feels the best? Take the grade school example of making a pros and cons list of the people we want to be our boy/girl friend? Let’s call our potential relationship candidates Troy and Abed. If, through the pros/cons process, they come out even, how do we decide who to pick? Mostly likely: Feeling.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Heuristic Learning&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In terms of the learning process, what is important in this example, is that we calculated our options. We knew that some decisions require thorough assessment, and thus weighed all the variables and at least attempted a logically sound choice. We can call this method of decision making &lt;em&gt;heuristics&lt;/em&gt;, (AKA ‘cognitive shortcuts’ or ‘rules of thumb’) a practical, and sometimes more efficient, approach to &lt;a href=&quot;http://www.sfu.ca/~jeffpell/papers/RomanyciaPelletierHeuristics85.pdf&quot;&gt;problem solving&lt;/a&gt;, whereby we may employ a commonly successful technique or model in assisting our own hunt for answers.&lt;label for=&quot;1.5&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;1.5&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Also check out the oft nefarious &lt;a href=&quot;https://projects.iq.harvard.edu/expose/book/interactions-heuristics-and-biases-making-decisions&quot;&gt;cognitive biases&lt;/a&gt; embedded heuristics especially the availability heuristic! &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;In this example, we attempted to root out for ourselves who the optimal boyfriend was using the timeless pros and cons list.&lt;/p&gt;

&lt;p&gt;All the boxes on the pros and cons checklist are weighted the same way, or that is to say, the characteristics we were judging Troy and Abed on have equally strong connections, so they came out even. Thus, some might say that the deciding factor, the “feeling” we used in grade school to make a final call, was in actuality the product of a stronger neural connection between where Troy’s conceptual reality lives in our heads and where Abed’s lives. This connection was fed via a simple emotional pull. But we’ll end this train of thought here, as emotional influences on neurological behavior goes beyond the scope of this series.&lt;/p&gt;

&lt;p&gt;Heuristic learning however, does not always use the same approach to solve a problem. Take for example, trying to locate Miso soup at a grocery store. How would you look for it? There are multiple options, perhaps the easiest of which is asking an employee, however if left to our own devices what do we do? Two other methods are 1.) Look in all the seemingly relevant aisles - oriental cooking, soup, sauces/condiments, shelf-stable items etc. 2.) Traverse every aisle, scanning up and down every shelf, until it’s located. While the first method is more efficient and usually successful, the second method guarantees success (that is if we know the store carries Miso), however it’s far more time-consuming. In the interest of heuristics, both of these processes work, and both show a logical effort.&lt;/p&gt;
&lt;figure class=&quot;fullwidth&quot;&gt;&lt;img src=&quot;/assets/img/Dilbert heuristics.jpg&quot; /&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;And what does this mean in terms of our brain’s learning? We decide how to proceed based on the information we have stored. But heuristics goes beyond the need to make a simple decision, it involves a process of logical reasoning in which we decipher how best to proceed according to relevant experience and current situations. And over time, we get better at calculating the correct method based on time after time of improving our odds with every cumulative experience.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;It’s not hard to believe that we would rely on the wisdom of past experience, especially our own, though how often have we repeated something we regret because we forgot what happened the first time, or else it seemed like a one time thing? But perhaps after the second time, we learn; and if not, than we remember that we should have. Even the insanity witticism, ever misattributed to Einstein, applies: “Insanity is doing the same thing over and over again, but expecting a different result”. While insanity is certainly an exaggeration of say, hitting your head on a low hanging doorway four times in a row, this aphorism implies that learning from these experiences over time is the more natural outcome; not learning, and thereby not changing our behavior, is thus illogical and unsustainable. If we don’t add these experiences up, and transcribe them into additional connections in our brains, than we can’t make better decisions in the future. And as it turns out, neural networks learn in much the same way.&lt;/p&gt;

&lt;p&gt;And thus, we come to Machine Learning.&lt;/p&gt;

&lt;p&gt;Part 3 (coming soon) will discuss how machine learning compares to this human form of heuristic learning.&lt;/p&gt;
</description>
        <pubDate>Wed, 17 Feb 2021 05:46:04 -0500</pubDate>
        <link>/articles/21/Part_Two_The-Genesis-of-Machine-Learning-Why-Neural-Networks-look-like-Our-Brains</link>
        <guid isPermaLink="true">/articles/21/Part_Two_The-Genesis-of-Machine-Learning-Why-Neural-Networks-look-like-Our-Brains</guid>
        
        
        <category>jekyll</category>
        
        <category>css</category>
        
      </item>
    
      <item>
        <title>Part One - The Genesis of Machine Learning: Why Neural Networks look like Our Brains</title>
        <description>&lt;p&gt;&lt;span class=&quot;newthought&quot;&gt;Machine learning is pretty wild. And as its functional forbearer, so is the human brain!&lt;/span&gt;&lt;/p&gt;
&lt;figure&gt;&lt;img src=&quot;/assets/img/Brains_ML/ML Brains 1.png&quot; /&gt;&lt;figcaption class=&quot;maincolumn-figure&quot;&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;!--more--&gt;

&lt;p&gt;&lt;strong&gt;Biomimicry: From Brains to Machines&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Computers were originally designed to solve complex rote problems; an algorithm would follow a formulaic structure to synthesize and calculate copious amounts of data before solving for a given output. These were generally time consuming, but not altogether unusual, for a human to complete. Nonetheless, computers came to replace many of the mathematicians who tediously plodded through equation after equation, with the possibility of starting from scratch from a single misplaced decimal point. Hidden Figures, a biography of early NASA engineers&lt;label for=&quot;1&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;1&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;It’s important to note that this book was more than just a historical capsule of early human computer work; it was also intended as a testament to the race and gender discrimination of the time and to celebrate the yet unrecognized work of black women in such a white male dominated sphere. &lt;/span&gt; &lt;label for=&quot;hiddenfigures&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;hiddenfigures&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/Brains_ML/The_official_poster_for_the_film_Hidden_Figures,_2016.jpg&quot; /&gt;&lt;br /&gt;&lt;em&gt;Hidden Figures&lt;/em&gt; (2016)&lt;/span&gt;, showcases some of the human side of this work through the &lt;a href=&quot;https://www.thehumancomputerproject.com/women&quot;&gt;efforts of women&lt;/a&gt; dedicated to calculating most of the behind the scenes engineering problems of early space travel. These women were, in fact, called computers! Now, however, that work is solved by computers of a less biological nature.&lt;/p&gt;

&lt;p&gt;Artificial intelligence (AI) became the natural progeny of this original computer when humans saw the potential for it to “&lt;a href=&quot;https://www.deeplearningbook.org/contents/intro.html&quot;&gt;think&lt;/a&gt;” for itself. If a computer can calculate all that information on its own (albeit after having been programmed by a human who continues to monitor its progress), why shouldn’t a computer make its own decisions? And what better framework than the human brain?&lt;/p&gt;

&lt;p&gt;The role of the brain here, in unlocking a new form of computation, is an example of &lt;em&gt;biomimicry&lt;/em&gt;, a creationary technique whereby we model the design of manmade technologies from biological entities &lt;label for=&quot;1.5&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;1.5&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;If you want more examples on the innovative technologies inspired by nature, check out the &lt;a href=&quot;https://biomimicry.org/&quot;&gt;Biomimicry Institute&lt;/a&gt;. &lt;/span&gt;. While this technique is dependent on what is being built, I believe it behooves humans to study nature’s processes as they have already been put through a rigorous round of methodological ‘testing’ (eons and eons over!) to refine a species’s functionality to its most efficient and sustainable version of itself; we call this process evolution. This does not mean that nature is the best fit for all manmade counterparts; evolution tailors the biology of an individual species according to its environment, and no environment is the same, thus no population is the same even within a species. As mentioned as well, the process of evolution occurs consistently and constantly, however the  results tend not to be significant or noticeable until thousands of years have past. Thus a species may not appear to fit its environment at any given moment, however biologically it is ever intending to. Nonetheless, we can still use the intentions and ‘design choices’ of evolution to inspire technologies with a comparable function.&lt;/p&gt;

&lt;p&gt;Which brings us to brains and computers. Like their mechanical counterparts, brains are complex, but relatively predictable, and more than that, they involve a system of inputs and outputs. Thus, it’s not difficult to understand the comparison between human cognition and computational “thinking”. After all, many machines learn in much the same way we do – hence the anthropomorphized terms of artificial &lt;em&gt;intelligence&lt;/em&gt; and machine &lt;em&gt;learning&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Today, machine learning (ML), &lt;a href=&quot;https://medium.com/swlh/deep-learning-101-artificial-intelligence-and-machine-learning-basics-5687a75212e3&quot;&gt;a subfield of artificial intelligence&lt;/a&gt;, has, in itself, become &lt;a href=&quot;https://machinelearningmastery.com/types-of-learning-in-machine-learning/&quot;&gt;a broad field&lt;/a&gt;, with different models for different learning approaches, which are subsequently built to synthesize and analyze data differently. We have also progressed so far into the AI discipline, that ML models have for the most part dropped the brain-framed training wheels and have taken on a life of their own that no longer mimic brain functions. But that doesn’t restrict us from examining the origin story of at least one kind of brain process and one kind of ML model.&lt;/p&gt;

&lt;p&gt;In the interest of comparing brain processes with ML, I will reduce our brains’ processing down to a logical structure, promoted by &lt;a href=&quot;https://plato.stanford.edu/entries/cognitive-science/&quot;&gt;cognitive scientists&lt;/a&gt;[&lt;a href=&quot;#_ftn3&quot;&gt;3]&lt;/a&gt; in illustrating cognition via &lt;a href=&quot;https://plato.stanford.edu/entries/connectionism/&quot;&gt;connectionism&lt;/a&gt;. This will in no way represent all actions or decision-making but will explain the theory behind basic processes. For this same reason, I will stick to explaining a &lt;em&gt;neural network&lt;/em&gt;, which is the ML model that finds its deepest roots in biological processes. In fact, originally known as an &lt;em&gt;artificial&lt;/em&gt; neural network, this model takes its name from its ‘predecessor’, &lt;em&gt;biological&lt;/em&gt; neural networks. As the ML version has grown in societal ubiquity (from &lt;a href=&quot;https://www.ijedr.org/papers/IJEDR1704192.pdf&quot;&gt;handwriting recognition&lt;/a&gt; to &lt;a href=&quot;https://arxiv.org/pdf/1708.08559.pdf&quot;&gt;self-driving vehicles&lt;/a&gt;), we have since dropped ‘artificial’ and ‘biological’ to make simply &lt;em&gt;neural networks&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;So how are neural networks like neural networks? Or in other words, how is a brain like a machine?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Our brains are comprised of billions of neurons. These are interconnected in a variety of unique ways with potentially unlimited connections. Unlike popular belief, the brain is not one big ball of neurons; instead, it has architectural symmetry and finely engineered spaces and corridors.&lt;/p&gt;

&lt;p&gt;In describing the brain, I’ll begin at one of the smallest units – a neuron. A neuron is essentially a relay station, set within an infinite chain of relay stations, receiving and sending forth information in the form of electrochemical signals. Each neuron has a cell body, with upwards of dozens of little tendrils shooting out called &lt;em&gt;dendrites&lt;/em&gt;. One of these tendrils is much longer than the rest and is in fact something else altogether - the &lt;em&gt;axon&lt;/em&gt;. And at the end of the axon are dozens of &lt;em&gt;synapses&lt;/em&gt;, which could be thought of as a pitching machine at a batting cage.  When a signal is fired, electricity received from neighboring neurons gathers in the cell body. Once enough signals have accumulated up to a certain threshold, the cell body fires an electrochemical pulse down the axon, which will in turn be rapid fire released through the synapses to neighboring cell’s dendrites which must grab them as if catching a baseball. Once those dendrites receive enough signals to pass the electrochemical threshold, they will fire an accompanying pulse down that axon. This happens instantaneously and in perpetuity through millions of other neurons until the signal reaches it goal.&lt;/p&gt;

&lt;figure class=&quot;fullwidth&quot;&gt;&lt;img src=&quot;/assets/img/Brains_ML/Structure-Of-Neurons-In-Brain.jpg&quot; /&gt;&lt;figcaption&gt;Anatomy of a neuron&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;When our brain is processing (thinking, remembering, reading, sensing etc.), these signals follow specialized neural pathways that are equipped to send a particular kind of information. For instance, when viewing an object, the image that appears in our eyes is deconstructed into basic info (color, shape, shading, perspective etc.) and sent to the &lt;em&gt;back&lt;/em&gt; of our brains to the occipital lobe via &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/books/NBK482504/&quot;&gt;the Lateral Geniculate Nucleus (LGN)&lt;/a&gt;.&lt;label for=&quot;3&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;3&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;&lt;a href=&quot;https://www.neuroscientificallychallenged.com/blog/know-your-brain-primary-visual-cortex&quot;&gt;This article&lt;/a&gt; provides an excellent breakdown of this process. &lt;/span&gt; One could say that the neurons in this channel were trained to recognize and relay only visual info, as they connect to parts of the brain designed to process visual stimuli – the eyes and the occipital lobe.&lt;/p&gt;

&lt;figure class=&quot;fullwidth&quot;&gt;&lt;img src=&quot;/assets/img/Brains_ML/1200px-Human_visual_pathway.png&quot; /&gt;&lt;figcaption&gt;Human visual pathway&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;The occipital lobe then processes the images and sends them to other parts of our brain for further analysis. If it’s a growling dog, that information may be disseminated &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3025529/&quot;&gt;through the amygdala&lt;/a&gt;, via various other lobes and channels, which will kick in a fight/flight reaction, which will engage our autonomic nervous system (ANS), which may cause us to run in a panic. This takes place in milliseconds.&lt;/p&gt;

&lt;figure class=&quot;fullwidth&quot;&gt;&lt;img src=&quot;/assets/img/Brains_ML/ML flow chart 4.png&quot; /&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;As a side note, stimuli, here, does not just refer to visual information. It could be somatosensory, as when touching a hot stove. It could be auditory, as when identifying a piece of music, or olfactory as when inhaling freshly made cinnamon buns. All of these coalesce into the representations in our minds that influence the decisions we make.&lt;label for=&quot;4&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;4&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;There are also multiple competing theories of how our perception works and especially the kinds of schema we create: check out an article that summarizes that &lt;a href=&quot;https://www.simplypsychology.org/perception-theories.html&quot;&gt;here&lt;/a&gt;. &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sounds Assembly Line-ish&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This explanation is vastly oversimplified (and for this example in particular, actually skips a few steps), but it may sound like another familiar historically-relevant process – &lt;em&gt;assembly lines&lt;/em&gt;, in which we see a step-by-step process that accumulates into a final product. We could say that each neuron represents a person with a specialty or task, each lobe or section of our brains represents a department, and between those is a conveyor belt that streamlines the packaged information from group to group. In other words, it has a linear orientation with one direction that starts and stops at the same place every time.&lt;/p&gt;

&lt;p&gt;In this way, we may prefer BF Skinner’s perspective&lt;label for=&quot;5&quot; class=&quot;margin-toggle sidenote-number&quot;&gt;&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;5&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;sidenote&quot;&gt;Skinner was originally from the era of behavioral psychology in which the mind (and by association the brain) was assessed by a person’s behavior, or else response to stimuli. This was also the era of Pavlov’s dog conditioning experiments – a perfect example of behavioral psychology in that Pavlov provided stimuli in the form of food (further associated with the sound of a bell) and tracked how the dogs responded (by drooling). &lt;/span&gt;, in that our brains are a “black box”. We can’t examine the internal workings; we can only monitor what comes out as a response to what goes in. Thus, one or multiple things is fed into one side of the box and something else entirely emerges on the other side. Likewise, at each destination in an assembly line, another part is added until a whole is complete.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;But wait – Not Quite&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To imply our brains are assembly line-ish is to have an incomplete understanding of how they work. In creating thousands of the exact same product, an assembly line does not loop back on itself, reconstruct the systematic assembly process based on a new part, or even switch the direction of the conveyor belt (this will make more sense later). The process is predetermined, and the work is the same regardless of individual variation. Our brains on the other hand, are constantly changing - renovating preexisting neuron structures, strengthening commonly used connections, removing and replacing unused ones. They have plasticity in other words.&lt;/p&gt;

&lt;p&gt;&lt;label for=&quot;blackbox&quot; class=&quot;margin-toggle&quot;&gt;⊕&lt;/label&gt;&lt;input type=&quot;checkbox&quot; id=&quot;blackbox&quot; class=&quot;margin-toggle&quot; /&gt;&lt;span class=&quot;marginnote&quot;&gt;&lt;img class=&quot;fullwidth&quot; src=&quot;/assets/img/Brains_ML/Black Box.jpg&quot; /&gt;&lt;br /&gt;Skinner’s idea of the human pyche.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;And while Skinner’s black box theory has largely been debunked, it does hold a key component for machine learning - inputs and outputs; stimuli go in, behavior comes out. Colloquially, ML models too are even referred to as “black boxes” in that when they are complex enough, it’s difficult to wholly understand their internal workings; although this may be &lt;a href=&quot;https://towardsdatascience.com/the-black-box-metaphor-in-machine-learning-4e57a3a1d2b0&quot;&gt;an over estimation&lt;/a&gt;. What Skinner’s theory neglects, however, at least for what is relevant here, is the iterative chain of processes it takes to receive an output, and furthermore, how that output stems from an accumulation of information gathered over time.&lt;/p&gt;

&lt;p&gt;Thus, we come to the next step in the brain/computer analysis. A brain is constantly observing new information. This new information is added to the preexisting information or stimuli (stored in our brains in the form of neuron clusters), for which a new paradigm is constructed or a new response is added to the list.&lt;/p&gt;

&lt;p&gt;In &lt;a href=&quot;Part_Two_The-Genesis-of-Machine-Learning-Why-Neural-Networks-look-like-Our-Brains&quot;&gt;part two&lt;/a&gt; of this series, I’ll talk about the iterative nature of human learning, before diving into the machine learning version of this process in part three.&lt;/p&gt;

</description>
        <pubDate>Sun, 07 Feb 2021 03:46:04 -0500</pubDate>
        <link>/articles/21/The-Genesis-of-Machine-Learning-Why-Neural-Networks-look-like-Our-Brains</link>
        <guid isPermaLink="true">/articles/21/The-Genesis-of-Machine-Learning-Why-Neural-Networks-look-like-Our-Brains</guid>
        
        
        <category>jekyll</category>
        
        <category>css</category>
        
      </item>
    
  </channel>
</rss>
