---
layout: post
title:  "Part One - The Genesis of Machine Learning: Why Neural Networks look like Our Brains"
date:   2020-02-07 08:46:04
categories: jekyll css
---
{% newthought 'Machine learning is pretty wild. And as its functional forbearer, so is the human brain!' %} 
{% maincolumn 'assets/img/ML Brains 1.png'  ''%}

<!--more-->

**Biomimicry: From Brains to Machines**

Computers were originally designed to solve complex rote problems; an algorithm would follow a formulaic structure to synthesize and calculate copious amounts of data before solving for a given output. These were generally time consuming, but not altogether unusual, for a human to complete. Nonetheless, computers came to replace many of the mathematicians who tediously plodded through equation after equation, with the possibility of starting from scratch from a single misplaced decimal point. Hidden Figures, a biography of early NASA engineers{% sidenote '1' 'It’s important to note that this book was more than just a historical capsule of early human computer work; it was also intended as a testament to the race and gender discrimination of the time and to celebrate the yet unrecognized work of black women in such a white male dominated sphere.'%} {% marginfigure 'hiddenfigures' 'assets/img/The_official_poster_for_the_film_Hidden_Figures,_2016.jpg' '*Hidden Figures* (2016)' %}, showcases some of the human side of this work through the [efforts of women](https://www.thehumancomputerproject.com/women) dedicated to calculating most of the behind the scenes engineering problems of early space travel. These women were, in fact, called computers! Now, however, that work is solved by computers of a less biological nature. 

Artificial intelligence (AI) became the natural progeny of this original computer when humans saw the potential for it to “[think](https://www.deeplearningbook.org/contents/intro.html)” for itself. If a computer can calculate all that information on its own (albeit after having been programmed by a human who continues to monitor its progress), why shouldn’t a computer make its own decisions? And what better framework than the human brain? 

The role of the brain here, in unlocking a new form of computation, is an example of *biomimicry*, a creationary technique whereby we model the design of manmade technologies from biological entities {% sidenote '1.5' 'If you want more examples on the innovative technologies inspired by nature, check out the [Biomimicry Institute](https://biomimicry.org/).'%}. While this technique is dependent on what is being built, I believe it behooves humans to study nature's processes as they have already been put through a rigorous round of methodological 'testing' (eons and eons over!) to refine a species's functionality to its most efficient and sustainable version of itself; we call this process evolution. This does not mean that nature is the best fit for all manmade counterparts; evolution tailors the biology of an individual species according to its environment, and no environment is the same, thus no population is the same even within a species. As mentioned as well, the process of evolution occurs consistently and constantly, however the  results tend not to be significant or noticeable until thousands of years have past. Thus a species may not appear to fit its environment at any given moment, however biologically it is ever intending to. Nonetheless, we can still use the intentions and 'design choices' of evolution to inspire technologies with a comparable function.

Which brings us to brains and computers. Like their mechanical counterparts, brains are complex, but relatively predictable, and more than that, they involve a system of inputs and outputs. Thus, it's not difficult to understand the comparison between human cognition and computational “thinking”. After all, many machines learn in much the same way we do – hence the anthropomorphized terms of artificial *intelligence* and machine *learning*. 

Today, machine learning (ML), [a subfield of artificial intelligence](https://medium.com/swlh/deep-learning-101-artificial-intelligence-and-machine-learning-basics-5687a75212e3), has, in itself, become a broad field](https://machinelearningmastery.com/types-of-learning-in-machine-learning/), with different models for different learning approaches, which are subsequently built to synthesize and analyze data differently. We have also progressed so far into the AI discipline, that ML models have for the most part dropped the brain-framed training wheels and have taken on a life of their own that no longer mimic brain functions. But that doesn't restrict us from examining the origin story of at least one kind of brain process and one kind of ML model.

In the interest of comparing brain processes with ML, I will reduce our brains' processing down to a logical structure, promoted by [cognitive scientists](https://plato.stanford.edu/entries/cognitive-science/)[[3\]](#_ftn3) in illustrating cognition via [connectionism](https://plato.stanford.edu/entries/connectionism/). This will in no way represent all actions or decision-making but will explain the theory behind basic processes. For this same reason, I will stick to explaining a *neural network*, which is the ML model that finds its deepest roots in biological processes. In fact, originally known as an *artificial* neural network, this model takes its name from its ‘predecessor’, *biological* neural networks. As the ML version has grown in societal ubiquity (from [handwriting recognition](https://www.ijedr.org/papers/IJEDR1704192.pdf) to [self-driving vehicles](https://arxiv.org/pdf/1708.08559.pdf)), we have since dropped ‘artificial’ and ‘biological’ to make simply *neural networks*. 

**So how are neural networks like neural networks? Or in other words, how is a brain like a machine?**

Our brains are comprised of billions of neurons. These are interconnected in a variety of unique ways with potentially unlimited connections. Unlike popular belief, the brain is not one big ball of neurons; instead, it has architectural symmetry and finely engineered spaces and corridors. 

In describing the brain, I’ll begin at one of the smallest units – a neuron. A neuron is essentially a relay station, set within an infinite chain of relay stations, receiving and sending forth information in the form of electrochemical signals. Each neuron has a cell body, with upwards of dozens of little tendrils shooting out called *dendrites*. One of these tendrils is much longer than the r rest and is in fact something else altogether - the *axon*. And at the end of the axon are dozens of *synapses*, which could be thought of as a pitching machine at a batting cage.  When a signal is fired, electricity received from neighboring neurons gathers in the cell body. Once enough signals have accumulated up to a certain threshold, the cell body fires an electrochemical pulse down the axon, which will in turn be rapid fire released through the synapses to neighboring cell’s dendrites which must grab them as if catching a baseball. Once those dendrites receive enough signals to pass the electrochemical threshold, they will fire an accompanying pulse down that axon. This happens instantaneously and in perpetuity through millions of other neurons until the signal reaches it goal. 

{% fullwidth 'assets/img/Structure-Of-Neurons-In-Brain.jpg' "Anatomy of a neuron" %}                            

When our brain is processing (thinking, remembering, reading, sensing etc.), these signals follow specialized neural pathways that are equipped to send a particular kind of information. For instance, when viewing an object, the image that appears in our eyes is deconstructed into basic info (color, shape, shading, perspective etc.) and sent to the *back* of our brains to the occipital lobe via [the Lateral Geniculate Nucleus (LGN)](https://www.ncbi.nlm.nih.gov/books/NBK482504/).{% sidenote '3' '[This article](https://www.neuroscientificallychallenged.com/blog/know-your-brain-primary-visual-cortex) provides an excellent breakdown of this process.' %} One could say that the neurons in this channel were trained to recognize and relay only visual info, as they connect to parts of the brain designed to process visual stimuli – the eyes and the occipital lobe. 

{% fullwidth 'assets/img/1200px-Human_visual_pathway.png' "Human visual pathway" %}                            

The occipital lobe then processes the images and sends them to other parts of our brain for further analysis. If it’s a growling dog, that information may be disseminated [through the amygdala](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3025529/), via various other lobes and channels, which will kick in a fight/flight reaction, which will engage our autonomic nervous system (ANS), which may cause us to run in a panic. This takes place in milliseconds. 

{% fullwidth 'assets/img/ML flow chart 4.png' "" %}                            

As a side note, stimuli, here, does not just refer to visual information. It could be somatosensory, as when touching a hot stove. It could be auditory, as when identifying a piece of music, or olfactory as when inhaling freshly made cinnamon buns. All of these coalesce into the representations in our minds that influence the decisions we make.{% sidenote '4' 'There are also multiple competing theories of how our perception works and especially the kinds of schema we create: check out an article that summarizes that [here](https://www.simplypsychology.org/perception-theories.html).' %}

**Sounds Assembly Line-ish**

This explanation is vastly oversimplified (and for this example in particular, actually skips a few steps), but it may sound like another familiar historically-relevant process – *assembly lines*, in which we see a step-by-step process that accumulates into a final product. We could say that each neuron represents a person with a specialty or task, each lobe or section of our brains represents a department, and between those is a conveyor belt that streamlines the packaged information from group to group. In other words, it has a linear orientation with one direction that starts and stops at the same place every time. 

In this way, we may prefer BF Skinner’s perspective{% sidenote '5' 'Skinner was originally from the era of behavioral psychology in which the mind (and by association the brain) was assessed by a person’s behavior, or else response to stimuli. This was also the era of Pavlov’s dog conditioning experiments – a perfect example of behavioral psychology in that Pavlov provided stimuli in the form of food (further associated with the sound of a bell) and tracked how the dogs responded (by drooling).' %}, in that our brains are a "black box". We can’t examine the internal workings; we can only monitor what comes out as a response to what goes in. Thus, one or multiple things is fed into one side of the box and something else entirely emerges on the other side. Likewise, at each destination in an assembly line, another part is added until a whole is complete. 

**But wait – Not Quite**

To imply our brains are assembly line-ish is to have an incomplete understanding of how they work. In creating thousands of the exact same product, an assembly line does not loop back on itself, reconstruct the systematic assembly process based on a new part, or even switch the direction of the conveyor belt (this will make more sense later). The process is predetermined, and the work is the same regardless of individual variation. Our brains on the other hand, are constantly changing - renovating preexisting neuron structures, strengthening commonly used connections, removing and replacing unused ones. They have plasticity in other words. 

{% marginfigure 'blackbox' 'assets/img/Black Box.jpg' "Skinner's idea of the human pyche." %}

And while Skinner’s black box theory has largely been debunked, it does hold a key component for machine learning - inputs and outputs; stimuli go in, behavior comes out. Colloquially, ML models too are even referred to as “black boxes” in that when they are complex enough, it’s difficult to wholly understand their internal workings; although this may be [an over estimation](https://towardsdatascience.com/the-black-box-metaphor-in-machine-learning-4e57a3a1d2b0). What Skinner’s theory neglects, however, at least for what is relevant here, is the iterative chain of processes it takes to receive an output, and furthermore, how that output stems from an accumulation of information gathered over time. 

Thus, we come to the next step in the brain/computer analysis. A brain is constantly observing new information. This new information is added to the preexisting information or stimuli (stored in our brains in the form of neuron clusters), for which a new paradigm is constructed or a new response is added to the list. 



In [part two](Part_Two_The-Genesis-of-Machine-Learning-Why-Neural-Networks-look-like-Our-Brains) of this series, I'll talk about the iterative nature of human learning, before diving into the machine learning version of this process in part three.


