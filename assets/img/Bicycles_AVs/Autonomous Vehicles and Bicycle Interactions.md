Autonomous Vehicles and Bicycle Interactions

**Contextual Background Story**

A friend of mine, who I’ll call Tom, came home one day with a bandaged hand, bruised face, and a general look of shock and bewilderment. He had just come from the hospital after hitting a car on his bike. A negligent happenstance for some, but a truly unlucky feat for Tom.

Here’s what he told me: 

While riding into town, post-COVID shutdowns, the streets were empty. This was around the start of quarantine, early April 2020 - hardly anyone was out. Nonetheless, Tom encountered one vehicle on his way.

After shooting down a short, but steep hill, Tom came up on a midsized SUV. He was still coasting from the downhill and hoped to use this momentum for an easier ride on the subsequent flat part coming into town. 

Tom was accelerating so fast from the momentum, he started making moves to pass the car ahead of him. As he was coming up on the car’s back right bumper, but still a reasonable distance behind, a pedestrian streaked across the road ahead of the car. As Tom put it, the guy appeared out of nowhere, whooped and sprinted through the crosswalk, then disappeared into a nearby park. And though the car was still a good distance from the crosswalk, it executed a full stop, causing the back wheels to swing into the bike lane. 

Tom, still trying to maximize his speed from the downhill, ran arm-first into the back window, while his face swung around and hit the side of the car. His hand, probably in trying to brace himself, punched through the bottom right corner of the back window and his arm went through all the way up to the shoulder. 

While this may seem like a clear case of an over-reactive driver, the driver, in fact, was not at fault. Instead, the car, a fresh-off-the-lot 2021 vehicle installed with an automatic emergency braking system (AEB), had made the decision to stop. Even though the car was far enough from the pedestrian for the driver to consciously reduce his speed, and even though the whooper/sprinter was speeding so fast through the crosswalk that the car wouldn’t have hit him regardless (according to Tom), the car had recognized a potential target and literally skidded to a halt. 

Both Tom and the driver paid for it, the driver in repairing his new car, and Tom with his medical bills and newly cracked bike frame. 

**So, what does this mean?**

I believe there are several takeaways from this story, perhaps the least of which is the question of when it’s prudent for a cyclist to rely on coasting. Tom had hoped to use the momentum from the downhill to ease his pedaling; I think most experienced cyclists have leant on passive energy for speed and ease of riding (plus, there’s a special kind of satisfaction derived from passing a car on your bike, especially while half-coasting). His determination to go faster, however, brought him in the line of fire. Which brings up another question: Is it right to pass another vehicle in such proximity when they are the only other vehicle on the roadway? Legality aside, is doing so considered inconsiderate if not rash? Tom acknowledges even that his attempt at overtaking may have been reckless. Given the flatness of the road, Tom’s experience as a cyclist, and the light manageability of his bike, he had no need to save himself the pedaling effort nor outpace the only other vehicle on the roadway. 

But the question I ultimately believe to be most poignant here is that of how autonomous vehicles (AVs) will coalesce with bicyclists in the future. I don’t believe one could truly attribute this accident to AEBs, given that they were attempting to save the driver and pedestrian from needless harm, however, the fact that an accident resulted nonetheless suggests a need for further analysis of how autonomous vehicles in general interact with bicyclists, as they may not have prioritized the bicyclist's safety as highly as they should have.

**But first – A Little Background**

What technology allows autonomous vehicles to be autonomous? And is it fair to question AVs in general despite Tom’s story only featuring AEBs?

In short, autonomous here means driver-less, or else, having little to no need for human supervision. But within this, AVs can be deconstructed into ascending levels of autonomy. The Society of Automotive Engineers (SAE) categorized AVs in 2013, and then [updated them again](https://www.sae.org/news/press-room/2018/12/sae-international-releases-updated-visual-chart-for-its-"levels-of-driving-automation"-standard-for-self-driving-vehicles) in 2018, developing 6 tiers of automation.[[1\]](#_ftn1) While it includes Level 0, where the car is completely manual, the automation evaluation spans from Level 1, in which the vehicle only makes suggestions to a human driver and occasionally takes over as evident in Tom's braking case, to Level 5, where the vehicle has complete control and passengers have confidence in not supervising. Between Levels 2 to 3, is the threshold between the human’s and vehicle's control; in other words, Level 3 signals the beginning of vehicle autonomy. Despite some company’s misleading advertising, like Tesla’s “[full self-driving](https://www.thedrive.com/news/26700/tesla-puts-full-self-driving-back-on-the-menu-but-its-not-what-you-think)” tech package, as yet, no company involved with AV technology has reached level 5. The table below details the different levels. 

![](/media/blaire/Data/hogwash/assets/img/Bicycles_AVs/Git hub bikes/AVs level of Autonomy 3.jpg)

Looking back at Tom’s story, we don’t see a Level 5 driverless vehicle. Instead, his experience features a human-driven car equipped with AEBs, a form of brake assist designed to help the driver identify and avoid head on collisions, putting this vehicle at a Level 0/Level 1, according to SAE’s interpretation.[2\]](#_ftn2) These brakes operate by receiving a command from a computer once it receives information from built-in sensors. When these sensors detect possible impending obstacles, they relay that data to the computer, which decides if they are indeed obstacles to be avoided; if so, the computer gives the word to brake. In other words, AEBs are a low-level form of artificial intelligence (AI). Like these AEB’s, AI makes decisions according to information it receives. While the AI of today is getting increasingly more complicated, analyzing a broader spectrum of data in more depth and outputting information akin to a human’s intelligence (and in many ways faster), at their core they operate by gathering, synthesizing, and processing data. Principally, this process is the same as an AEB's decision making, as well as, AV's decision making.

(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image002.jpg) [Side image: AEBs]

Thus, despite Tom’s brush with what could be considered a minor version of AI, these brakes are in fact the immature fledglings of a fully autonomous vehicle. More than that, the AVs of today are intended by some to be the prototype of a nationwide fleet of vehicles. Projections from the [GHSA](https://www.ghsa.org/resources/spotlight-av17)  (and many others like it) predict anywhere from 20 - 40% of vehicles manufactured by 2040 will be autonomous. Already, the technology that enables AVs has grown exponentially in the last decade, to the point where we currently see functioning Level 4 vehicles on roadways worldwide (albeit on a trial level as most are still under supervision, and prone to adjustments as the systems run into novel situations). And progress begets progress, as they say. Given this projected eventuality, I believe it’s fair to interrogate the nature of AVs in general, as they are poised to be the next greatest technological advancement since the bread slicer gave us sliced bread.

 

(/assets/img/clip_image002.jpg)[Side image: Couldn’t help myself. Evolution of Autonomous Vehicles on Screen]

!(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image003.png)! (file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image005.jpg) 

 

!(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image007.jpg)

[Side Image – timeline of companies predicted to transition to Level 5 automation]

 

Driverless-ness, however, is a tall order. While certainly more than the sum of its parts, when disassembled, we can see the complex systems that AVs must employ to function. Among technologies like GPS, automatic braking, steering, and locking, AVs have what Alan Amici, vice president of TE Connectivity, an automotive company at the forefront of sensory technology, identifies as the 3 most essential AV elements: sensors, connectivity, and software/control algorithms.

*Sensors*

Sensors are pivotal to the car’s ability to navigate and more than that, they do the data groundwork, feeding information to the other systems to build from. Sensors must observe their surroundings, detect objects on all sides, identify curves in the road, etc. We see these sensors in the form of 3 basic technologies working simultaneously: 360-degree LIDAR and radar for object detection[[1\]](#_ftn1), cameras for cross-checking object recognition, and ultrasound for park assist. 

These provide the AVs with a visual field comparable to the human eye, allowing them to “see” as a human would and orient themselves in relation to the objects around them. While at the moment sensors may not out-compete a human eye, several benefits of this technology are that sensors are constantly vigilant, consistent in their estimations, and attending to all sides of the vehicle at once. 

!(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image009.jpg)

*Algorithms*

All this sensory data, however, is useless to a system that can’t make confident, human-esque decisions; it needs an on-deck computer system to compile information and learn from the data accumulated until it has developed a situationally-aware, and in some ways, superhuman system[[2\]](#_ftn2). In other words, it needs AI. Essentially like a teenager with a learner’s permit, the system garners skill through experience. And in doing so, the algorithm learns to discriminate between ambiguous objects like a plastic bag and a child, a shady patch and a pothole, or highway construction and a cyclist. For the most part, AVs use neural networks, a machine learning model not unlike a human brain. The networks, once fed a sufficient amount of images, let's say of a bicycle (think of any of the captcha assignments to prove non-robotness), will eventually ascertain for itself what a bicycle is without being told. The images prime the model in a training setting, so it understands what it was looking at on the roadway. Once it identifies the bicyclist, the model can then make a decision. Its next move may be to consciously give the bicyclist 3 feet of breathing room while passing as the law requires. Among the 50+ companies involved with autonomous vehicles, there are dozens of models available. I’ll discuss one company's model in more detail later.

Not only do these models need to identify *what* they are looking at, they are also need to reconcile speed and direction of surrounding objects. And in doing so, an algorithm should be able to predict the movements of these objects to inform its own navigational decisions. For instance, if the vehicle wants to switch lanes, it must determine if any entity is currently occupying the space it seeks to fill, or if there is an approaching vehicle about to pass. If so, it must calculate that vehicle’s speed and adjust accordingly. Alternatively, if a deer runs across the road, while perhaps unpredictable, it would be useful to know if that deer would already be out of the lane by the time the vehicle gets there. Thus, in calculating the deer’s speed and direction, or in other words, its velocity, the AI may determine if it only needs to slow down instead of stop, perhaps saving its passengers unnecessary stress.

!(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image010.jpg)[side image: algorithms]

*Connectivity*

Lastly, while the AVs are fully operational with just sensors and algorithms, they also need input from surrounding vehicles or wireless hubs (i.e. connectivity) if they are to be more efficient and operate in proximity. If a vehicle decides to stop because it thinks the plastic bag is a child, it needs to provide a forewarning to the next vehicle that it’s stopping, so the next car may simultaneously and safely stop or else provide a wide berth. Additionally, fleets of AVs on the roadway, if not interconnected, may be dangerous, if not simply inefficient. Take for example two AVs arriving at an intersection at the exact same time. While AEBs may prevent them from running into each other, without the ability to communicate, the AVs may become locked in an interminable stalemate as they attempt to navigate past each other. That may only occur, however, if they aren’t able to communicate their intentions and synchronize their movements. Thus, AVs cannot operate on independent systems. Check out the image below for more examples where connected AVs can avoid tricky situations.

![](/media/blaire/Data/hogwash/assets/img/Bicycles_AVs/V2V.png)

More than that, connectivity could boost efficiency overall. Traffic could synchronize[[3\]](#_ftn3), eliminating the-mile-long start/stop jerking; stop lights could become non-existent. In a large intersection, vehicles would automatically make space for each other. And, an overarching algorithmic system, essentially acting as an air traffic controller, could calculate each vehicle’s route, determine where each AV will be at any given moment, and ultimately, minimize everyone’s time in traffic. Vehicles could also receive moment by moment reports from traffic and accident centers, like The Department of Transportation, local newscasters, or Google Maps. This could be a boon for a vehicle’s passengers; AVs could automatically switch routes due to road closures, traffic, or iciness, saving passengers time and reducing contact with safety hazards. 

It’s also interesting to note where the connectivity occurs. The picture below summarizes the big 5 in AV wireless tech, though it doesn’t identify the individual objects such as trees, buildings, rocks and the like, which may have sensors attached to them to inform AVs of their location. This could be helpful in circumnavigating unique roadway situations where a tree, for instance, is situated very closely to the road, and the vehicle may mistake it for a pedestrian or cyclists, of which, it would need to provide extra space for.

[Side Image-Connectivity]

*Fully Operational System*

Collectively, these technologies form a functional efficient system that, with enough sensors positioned correctly, combined with reliable programming and wireless information boosts, could be more preferable than conventional vehicles. Despite their potential, however, this technology is working faster than the policies to regulate it. Without firm regulatory guidelines, not all of the AVs on the market today are put through the same standard of safety procedures with the same level of testing and algorithmic capabilities. Both Tesla and Uber have infamously mis-advertised or cut corners on their products. This leads me to be skeptical but hesitantly excited for the potential of these vehicles to revolutionize transportation and restructure society in ways that could be more sustainable, efficient, and humane. But before any of that is possible, we need regulation, standardization, and a thorough look at what these vehicles are capable of today.



**Elaine Herzberg**

In March 2018, [Elaine Herzberg](https://usa.streetsblog.org/2019/03/08/uber-got-off-the-hook-for-killing-a-pedestrian-with-its-self-driving-car/) was struck and killed by an Uber owned self-driving vehicle out for a test drive, as she walked her bike across an Arizona street. She was the first AV-related pedestrian fatality. It should be noted, however, that a backup driver was behind the wheel (watching The Voice) and the AEBs had been disabled, so the exact degree of the car’s (and by extension Uber’s) fault is indeterminate.[[4\]](#_ftn4) It was presumed that the car recognized neither Herzberg nor the shape of her bag-laden bicycle, suggesting a lack of thorough vetting for AV’s bicycle identification models. And similarly to Tom’s sprinting pedestrian, she appeared out of nowhere, “like a flash” according to the driver, which is what the Tempe Arizona Police Chief Sylvia Moir told a local paper. The difference between Tom’s and Elaine’s incidents, however, is that Tom was the unfortunate recipient of an operational braking system, attempting to circumvent collision with a pedestrian. Elaine on the other hand, was the pedestrian in this case, however, the system was not operational, nor did it detect her existence until it was too late.

 !(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image014.jpg)!(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image015.jpg)!(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image017.jpg) 

Without a clear account of what happened, especially from Elaine’s perspective, it’s difficult to parse out the nuance. But essentially, even if the brakes were operational it appears as if the vehicle wouldn’t have had the capacity to avoid her let alone immediately identify her as a human. According to [a report](https://www.ntsb.gov/investigations/AccidentReports/Reports/HAR1903.pdf) put out by the National Transportation Safety Board (NTSB) after the accident, the vehicle had flashed a warning of a potential object in the roadway, but only 5.6 seconds before impact. Within this minute period, the vehicle classified Elaine as another vehicle, an unidentifiable object, a pedestrian, and a bicyclist. Once it finally decided Elaine was an accident waiting to happen, it had 1.2 seconds to react, however, because the brakes had been disabled, it was unable to do so. While ample theoretical inquiry could debate the culpability of Uber and its technological corner-cutting, what is important for this article is why the system wasn’t able to identify her, and furthermore, predict her movements (i.e. how fast she was going, what orientation she exhibited, what direction she was going). And with that, how much did her bike affect the way she was perceived?

**Weeds: Autonomous Vehicle Stats**

*AV Collisions*

Despite popular sensationalist belief, Elaine’s tragedy was not usual. Or else, her accident – a head on collision – was not representative of most of the kinds of accidents that self-driving vehicles engage in. In the US especially, we are prone to think that fatal high-speed collisions are the norm for the AVs, given media coverage of such incidents as Elaine’s and also Tesla’s [numerous highway crashes](https://insideevs.com/tag/tesla-autopilot/). Nonetheless, [tentative research](http://www.umich.edu/~umtriswt/PDF/UMTRI-2015-34_Abstract_English.pdf]) from 2019 has shown that in actuality, rear-end collisions encompass the majority of AV accidents at 64.2%, a staggeringly high number considering that the next most frequent accident type for AVs are angle crashes (those that mostly occur at intersections with cars going at perpendicular directions or turning onto another roadway) at 31.4%. Even [conventional vehicles](https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812981) (CVs) with a human driver don’t get close to that rear ending stat; only 28.3% of motor vehicle accidents in the US are rear ends. Though rear-end and angle collisions are still the first and second most common crash type for conventional vehicles. And on top of all that, AVs are far more likely to be rear-ended by other vehicles than to do the rear-ending themselves. It’s speculated that this is due to the unconventional way AVs drive. In sticking to the letter of the law as they are programmed to do, they tend to confuse human drivers who are more likely to speed, tailgate, hug the side line, shoot the gaps etc. And, as AVs are hyper aware of any pedestrians or vehicles in front of them, they are more likely to fully stop for their protection, encountering situations where human drivers may instead slow down, make a wide berth, or, if what the AV was perceiving wasn’t actually another person at all, keep on at normal speed.

Perhaps not surprisingly, because of this, AVs have a higher accident rate per miles traveled than conventional vehicles. A study from 2015 calculated that human drivers averaged anywhere from 1.9 – 4.1 crashes per million miles traveled.[[5\]](#_ftn5) AVs, on the other hand, average about 9.1. An alarming stat on the surface; however, as these accidents are largely in the form of rear-endings from other vehicles, they are not nearly as fatal or injurious as conventional vehicle crashes. On top of that, almost ¾ of the crashes occurred with the AV going at a speed of 5mph or lower; however, this again, is probably due to the excessively cautious driving style employed by AVs. But it should be noted that the report doesn’t detail how fast the other vehicles were going and thus how great of an impact the other drivers felt. 

*Limitations*

While this study, [and others like it](https://www.sciencedirect.com/science/article/pii/S2352146520301654), provide confident results, three caveats need to be recognized. 1.) AVs, unfortunately, don’t exist in the quantities needed to make meaningful comparisons with conventional vehicles. The data acquired from the DMV[[6\]](#_ftn6) of combined accident rates for conventional vehicles totals nearly 3 trillion miles as opposed to 1.2 million by AVs. Put another way, that’s 1 AV mile for every 2,500,000 CV miles. In fact, [a report](https://www.rand.org/content/dam/rand/pubs/research_reports/RR1400/RR1478/RAND_RR1478.pdf) released by the RAND corporation (a nonprofit research institution) concludes that 100 AVs driving 24 hours a day, 365 days of the year, at an average speed of 25 mph, would need to drive for 12.5 years, or 275 million miles, to conclude with 95% confidence that their failure rate leads to at most 1.09 deaths per 100 million miles. That's a lot of numbers to process, but in essence, the sample size of the previous study, and all others like it, will be too small to make any generalizable statements until AVs have driven enough miles. 2.) Another limitation the study notes is the context of the vehicle testing, or more specifically, where the vehicles were not tested – icy, stormy, or geographically unstable areas, or otherwise dangerous conditions. It’s unclear how many CVs are involved in accidents due to weather or roadway circumstances; it should thus be noted that AV collision results, could significantly differ depending on their location. 3.) The report specifies that the AVs were not at fault for any accident they were involved in, however, it’s unclear what they mean by “fault”. It could mean that the AVs didn’t do the colliding, (they were in fact the collidees) and by that metric, it wasn’t the AV’s fault. Or it could mean, that the situations where the AVs stopped or slowed and the CVs hit them were entirely justified (as in there may have been a pedestrian in the road) and, therefore, were not the AVs fault. However, as it has been suggested that so many rear-end accidents with AVs occurred because human drivers were surprised by the AVs behavior, I believe there is room to allow for AV culpability. If AVs are not following the intuitive rules of the road that every other driver subscribes to, they may lead to accidents that may not have happened otherwise. Thus, I believe it’s prudent to reserve judgment on the exact safety viability of these stats until more information can be obtained.

**So, what does all this have to do with bikes?**

*A Little Background*

Bicyclists have had a contentious history with vehicles. Given their lack of protection, meeting in unexpected road combat with a vehicle will more than likely result in the [cyclist being injured](cyclist injured) if not killed. In [2017](https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812765), 783 bicyclists died on US roadways[[7\]](#_ftn7); 96% (or 753) of those deaths involved a vehicle. Most of the time, this is due to simply not seeing the cyclist; bikes are small and often situated below the driver’s line of sight, and because of their maneuverability, they zip through traffic, perhaps coming up on a driver unawares; a driver may also neglect to check, as happens when opening a door into a bike lane. Either way, drivers are liable to fatally injure a cyclist whether they realize it or not. Take for example, [Katie Mckenna](https://www.rd.com/article/run-over-by-an-eighteen-wheeler/), a New York cyclist turned author and motivational speaker. She was run over by a semi-truck when it failed to notice her while making a right turn at an intersection. In [her book](https://www.amazon.com/How-Get-Run-Over-Truck-ebook/dp/B01LY9PYBR), she pulls no punches when identifying bicyclist’s vulnerability on the roadway; the first line queries, “So, how do you get run over by a truck? My first recommendation is to ride a bicycle”. According to her book, she signaled in every way possible that she was there. This is a sensationalist example, but one that exemplifies a common problem bicyclists have with surrounding vehicles – a lack of attention – a problem AVs too are not yet exempt from, though many are excited by their potential. 

 !(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image019.jpg)[Side Image: How to Get Run Over by a Truck]

*Bike/AV Collisions Stats*

AV manufacturers have done a remarkable job in ensuring the welfare of cyclists, considering that bicycle accidents with CVs somewhat consistently account for [less than 5%](https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/812765) of total annual incidents. However, bicyclists, and pedestrians as well, are considered vulnerable road users (VRU), and need extra precautionary measures from the stronger road users. According to the NTHSA, 82% of the cyclist deaths in 2017 were head-on collisions, where a vehicle hit a bicyclist head on; thus in installing hearty frontward sensors to detect cyclist or pedestrian movements, AVs can eliminate much of the problems that bicyclists have.

I wasn’t able to find much data pertaining to specifically AV and bicycle collisions. What information is available tends to combine pedestrian and bicyclists together into the VRU category, thus it's difficult to tell how often bicyclists alone have these incidents. For instance, Waymo, the Google self-driving vehicle subsidiary, releases reports every year detailing their research findings. In 2019, Waymo was involved in 1 actual and 2 simulated accidents in which a pedestrian or cyclist ran into a stationary or low speed AV. It isn’t clear how many miles these vehicles traveled, nor how many accidents they engaged in. And again, cyclists and pedestrians were included in the same category, presumably because their numbers are so low. 

What is important here however, is that As noted, AVs are apt to stop given any semblance of a figure in their frontward scopes, some of which is cautionary behavior, others are misidentifying information in their visual field. For instance, Tesla vehicles have been noted to confuse the side of close semi-truck with a far-off billboard as what happened in this fatal crash. Teslas have also mistaken gas station flags adorned with brightly colored loopy writing for stop lights. Google vehicle’s, while acting in a preferably cautious manner, noticed movements of a bicyclist maintaining balance at an intersection as a sign that the cyclist was moving. Thus, what I’ve gathered the bicycle accidents with AVs tend to be unconventional. 

Similarly, looking back at Tom’s situation, we can see that it was far from extreme; there were no causalities and no additional vehicles involved, and in relation to AI vehicle collisions, certainly not the norm. Tom was behind the car, and due to its braking system, crashed into it, not necessarily because it didn’t see him, but because in trying to avoid harm to someone else, it slid into his lane. Between Tom’s and Elaine’s incidents, is the question of bikes. Tom may have escaped unscathed if the vehicle didn’t swerve into his lane. So, does that suggest a lack of oversight on how the vehicle, upon braking from high speeds, may swerve into a designated and frequently ridden bike lane? And in doing so, is the system designed to prioritize objects in front rather than on either side? If so, the AI in question may not be accounting for bicyclists riding only feet away from the vehicle.

*Bike Troubles*

As it turns out, AVs have been having trouble with bikes since their inception. A [Slate article](https://slate.com/technology/2018/02/self-driving-cars-struggle-to-detect-cyclists-bicycle-to-vehicle-communications-arent-the-answer.html) cites UC Berkeley research engineer Steven Shladover acknowledging: “Bicycles are probably the most difficult detection problem that autonomous vehicle systems face.” And it’s no wonder; they are small, swift, and unpredictable. Despite pedestrians lack of protective gear and generally small stature in comparison with a vehicle, bicyclists being quick and nimble, are the most likely to catch a driver unawares. And unlike cars, which have a blocky shape with lots of mass and volume, bikes have a smaller inconsistent shape. Even when bicyclists follow safe legal procedures for switching lanes, the AI can have difficulties interpreting the shapes in its visual field; a bike gets bigger, in a 2D sense, when going from the back to the side views. When viewing the back of a bike, it looks small and compact. And without a holistic understanding of a bicycle’s appearance, it would be hard to predict how far forward the bike extends. So, when viewing a bike from the side, it seems to get bigger and change shape, a seeming improvement for an automated vehicle’s sensing capabilities. However, even this is easily misinterpreted as the side view has more negative space between the wheels and the frame. Not only that but putting an arm out to signal direction, wearing eye catching clothing, or attaching saddle bags and baskets can change the appearance of a bicycle.

!(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image021.png)![(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image023.jpg)![img](file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image027.j!(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image029.jpg)!(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image031.jpg)

[Side images: Unusual bike shapes that could further confuse an AV’s AI] 

Tom's situation, while unorthodox, mimics much of the kinds of accidents AVs are used to. He rear-ended the vehicle after it jumped to a sudden conclusion; and more than that, he wasn't even given a chance to slow down, which he may have if the vehicle had acted more gradually. In other words, the vehicle didn't behave as a CV would. And while it's commendable that it noticed the pedestrian and sought to prevent harm, without prior notice, instead it was Tom who was harmed. And in this situation, Tom assumes that he would not have encountered the pedestrian at all; with a more nimble transport, he had a good chance of maneuvering around the person without stopping. Nonetheless, Tom escaped remarkably unscathed; instead of punching the metal frame and shattering his hand, he punched through the glass. He also didn't receive any significant bruising, nor did his head smash straight into the metal frame; though he was wearing a helmet which protects the surface of the head, it does little for CTEs from brain jostling. 

*Right Turns*

Tom’s situation too can shed light on similar events. When San Francisco began rolling out Uber’s new autonomous taxi line in 2016, San Francisco’s Bicycle Coalition wrote a [blog post](https://sfbike.org/news/a-warning-to-people-who-bike-self-driving-ubers-and-right-hook-turns/) detailing the negligent nature of the vehicles’ right-hand turns.[[8\]](#_ftn8) These were described as a “right hook” through the bike lane, instead of a gentle cognizant merge, suggesting either a lack of AI sensors or else recognition of bicyclists when located to the vehicle’s right, or a lack of AI training on how to properly merge into the bike lane when executing a right turn. Uber’s suggested fix here, was to ensure a human driver take over to avoid the AI from negligently rounding the turn, a short-term solution for a long-term problem.

!(file:///C:/Users/bleoh/AppData/Local/Temp/msohtmlclip1/01/clip_image039.jpg) [Side image: Right hook]

Thus, both Tom’s and Elaine’s experiences epitomize just one potential issue in an emerging technology, or at least, a known pattern in need of further redress, that is bicycle identification and consideration. 

 

 

 



 

 



------

[[1\]](#_ftnref1) [This article](https://www.thedrive.com/article/16916/lidar-vs-radar-pros-and-cons-of-different-autonomous-driving-technologies#:~:text=First of all%2C what's the,for Light Detection And Ranging.&text=Radar uses radio waves to,light rather than radio waves.) discusses how LIDAR and radar work, their differences, pros and cons, and which of the two sensors individual AV companies prefer

[[2\]](#_ftnref2) I won’t go into the different kinds of AI models employed by AV’s, however [this article](https://www.jdsupra.com/legalnews/the-basics-of-autonomous-vehicles-part-35016/) details many of the commonly used algorithms.

[[3\]](#_ftnref3)Check out [this video](https://www.youtube.com/watch?v=iHzzSao6ypE&t=253s) on how phantom traffic forms and [this video](https://www.youtube.com/watch?v=TNokBgtSUvQ&t=255s) for a more detailed look. While I prefer the first video because it provides more information in less time, the animation in the second video is hard to beat.

[[4\]](#_ftnref4) Check out [this Medium article](https://onezero.medium.com/who-killed-elaine-herzberg-ea01fb14fc5e), which features an excerpt from *Who’s Driving Innovation*, a book by University of College London Associate Professor in Science and Technology Studies, Jack Stilgoe. It discusses every individual agent’s involvement and culpability in this tragedy, and how we can learn from it for future innovation

[[5\]](#_ftnref5) The variability is due to how many crashes tend not to be reported. Though 1.9 cpmm is a fixed number from the DMV, the researchers here estimated unreported ones as well, and put the actual US crash rate at about 4.1pmm.

[[6\]](#_ftnref6) AV manufacturers are required to report any crash or collision involving AVs within 10 days to the DMV.

[[7\]](#_ftnref7) This report was released by the National Highway Traffic Safety Administration. Unfortunately, I couldn’t pin down more recent stats. Also, they refer to cyclists as pedalcyclists here to include unicycles, tricycles, nonmotorized vehicles, and the like. I will only use bicyclists and cyclists in this article; thus, it’s important to note that these stats may be skewed as they include other kinds of pedal-operational vehicles.

[[8\]](#_ftnref8) This series isn’t designed to target Uber. But Uber more than any other emerging AV tech company has been error prone, mostly for the fact that they are rushing to be the first AV in the market, and it’s been reported, that in doing so, they’ve flouted many of the safety tests and thorough tech that their competitors engage in.

------

[[1\]](#_ftnref1) It’s worth noting, that since SAE created the autonomy levels, they have taken on a life of their own. It’s unclear if SAE sanctioned any of the changes or if they were simplified via the telephone game process. But many other sources would not characterize AEBs as Level 0, only Level 1, however, SAE leaves room for them in Level 0.



------

[[2\]](#_ftnref2) Before the update there were only 5 tiers going from Levels 0-4. As technology progressed, Level 4 developed parts (a) and (b). It was eventually bisected into two separate levels. Images detailing AV tech, history, and projections refer to fully autonomous as Level 4 or Level 5 depending on when they were created.
